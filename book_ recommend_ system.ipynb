{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPk3qUwezc4c0AXUp9KtcS2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBel-YaP2bP_","executionInfo":{"status":"ok","timestamp":1700286476520,"user_tz":-540,"elapsed":3403,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"b6e50013-d1de-427d-fba6-6d65ee6cc376"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# 구글 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import joblib\n","path = '/content/drive/MyDrive/해커톤/data/data.pkl'\n","data = joblib.load(path)"],"metadata":{"id":"zPUa_h9M21XA","executionInfo":{"status":"ok","timestamp":1700286477190,"user_tz":-540,"elapsed":673,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import joblib\n","path = '/content/drive/MyDrive/해커톤/data/cosine_data.pkl'\n","content_df = joblib.load(path)"],"metadata":{"id":"PRl5y15y5cgI","executionInfo":{"status":"ok","timestamp":1700287103854,"user_tz":-540,"elapsed":608,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","# pickle 파일 불러오기\n","collaborative_df = joblib.load('/content/drive/MyDrive/해커톤/data/collaborative_data.pkl')"],"metadata":{"id":"T1wJacCo725Y","executionInfo":{"status":"ok","timestamp":1700286477190,"user_tz":-540,"elapsed":5,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(data.shape)\n","print(content_df.shape)\n","print(collaborative_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVHKcuuL8cT_","executionInfo":{"status":"ok","timestamp":1700286477191,"user_tz":-540,"elapsed":5,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"ba594252-7333-456c-a899-fac76749bb98"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(534, 15)\n","(534, 4)\n","(15510, 5)\n"]}]},{"cell_type":"code","source":["# from mecab import MeCab 설치\n","!pip install konlpy pandas seaborn gensim wordcloud python-mecab-ko wget svgling"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45OMppUn8hdv","executionInfo":{"status":"ok","timestamp":1700284082092,"user_tz":-540,"elapsed":15663,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"9a076049-e7a4-4c13-83e8-4033674daee6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.2)\n","Collecting python-mecab-ko\n","  Downloading python_mecab_ko-1.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (573 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.9/573.9 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting svgling\n","  Downloading svgling-0.4.0-py3-none-any.whl (23 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (9.4.0)\n","Collecting python-mecab-ko-dic (from python-mecab-ko)\n","  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting svgwrite (from svgling)\n","  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=e999a505688ac555e3288ae3b3052f3c0c240d53c18b48920f361616946b24e0\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget, python-mecab-ko-dic, svgwrite, python-mecab-ko, JPype1, svgling, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0 python-mecab-ko-1.3.3 python-mecab-ko-dic-2.1.1.post2 svgling-0.4.0 svgwrite-1.4.3 wget-3.2\n"]}]},{"cell_type":"code","source":["# Py-Hanspell\n","# 한국어 전처리 패키지\n","# 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지로써 맞춤법을 고친 문장을 반환\n","# 네이버 맞춤법 검사기 API를 사용하는 것이므로 500자 이상은 불가능..\n","\n","!pip install git+https://github.com/ssut/py-hanspell"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrBXxfMf8txq","executionInfo":{"status":"ok","timestamp":1700284102274,"user_tz":-540,"elapsed":20186,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"8ea16926-c90e-49f6-9d29-5a6e84c5eed3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/ssut/py-hanspell\n","  Cloning https://github.com/ssut/py-hanspell to /tmp/pip-req-build-wc7faw3s\n","  Running command git clone --filter=blob:none --quiet https://github.com/ssut/py-hanspell /tmp/pip-req-build-wc7faw3s\n","  Resolved https://github.com/ssut/py-hanspell to commit fdc6ca50c19f1c85971437a072d89d4e5ce024b8\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from py-hanspell==1.1) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2023.7.22)\n","Building wheels for collected packages: py-hanspell\n","  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4811 sha256=a2503a82b69e7d9b4b482a660386bc3236214a4373e9aac26207a849bacd13e6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xub1wv3a/wheels/8a/a2/42/dd59a6ea430825c9ca823f2012a3f02cc7b272eff1618e6baf\n","Successfully built py-hanspell\n","Installing collected packages: py-hanspell\n","Successfully installed py-hanspell-1.1\n"]}]},{"cell_type":"code","source":["# # -*- coding: utf-8 -*-\n","# \"\"\"\n","# Python용 한글 맞춤법 검사 모듈\n","# \"\"\"\n","\n","# import requests\n","# import json\n","# import time\n","# import sys\n","# import re\n","# from cachetools import TTLCache\n","# from urllib import parse\n","# from collections import OrderedDict\n","# import xml.etree.ElementTree as ET\n","\n","# from . import __version__\n","# from .response import Checked\n","# from .constants import base_url\n","# from .constants import CheckResult\n","\n","# _agent = requests.Session()\n","# PY3 = sys.version_info[0] == 3\n","# cache = TTLCache(maxsize = 10, ttl = 3600)\n","\n","# def read_token():\n","#     try:\n","#         TOKEN = cache.get('PASSPORT_TOKEN')\n","#         return TOKEN\n","#     except KeyError:\n","#         return None\n","\n","# def update_token(agent):\n","\n","#     html = agent.get(url='https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=맞춤법검사기')\n","\n","#     match = re.search('passportKey=([a-zA-Z0-9]+)', html.text)\n","#     if match is not None:\n","#         TOKEN = parse.unquote(match.group(1))\n","#         cache['PASSPORT_TOKEN'] = TOKEN\n","#     return TOKEN\n","\n","# def _remove_tags(text):\n","#     text = u'<content>{}</content>'.format(text).replace('<br>','')\n","#     if not PY3:\n","#         text = text.encode('utf-8')\n","\n","#     result = ''.join(ET.fromstring(text).itertext())\n","\n","#     return result\n","\n","# def get_response(TOKEN, text):\n","\n","#     if TOKEN is None:\n","#         TOKEN = update_token(_agent)\n","\n","#     payload = {\n","#         'passportKey' : TOKEN,\n","#         'q': text,\n","#         'color_blindness': 0\n","#     }\n","\n","#     headers = {\n","#         'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n","#         'referer': 'https://search.naver.com/',\n","#     }\n","\n","#     r = _agent.get(base_url, params=payload, headers=headers)\n","#     data = json.loads(r.text)\n","\n","#     if 'error' in data['message'] :\n","#         r = get_response(update_token(_agent), text)\n","\n","#     return r\n","\n","\n","# def check(text):\n","#     \"\"\"\n","#     매개변수로 입력받은 한글 문장의 맞춤법을 체크합니다.\n","#     \"\"\"\n","#     if isinstance(text, list):\n","#         result = []\n","#         for item in text:\n","#             checked = check(item)\n","#             result.append(checked)\n","#         return result\n","\n","#     # 최대 500자까지 가능.\n","#     if len(text) > 500:\n","#         return Checked(result=False)\n","\n","#     start_time = time.time()\n","#     r = get_response(read_token(), text)\n","#     passed_time = time.time() - start_time\n","\n","#     data = json.loads(r.text)\n","#     html = data['message']['result']['html']\n","#     result = {\n","#         'result': True,\n","#         'original': text,\n","#         'checked': _remove_tags(html),\n","#         'errors': data['message']['result']['errata_count'],\n","#         'time': passed_time,\n","#         'words': OrderedDict(),\n","#     }\n","\n","#     # 띄어쓰기로 구분하기 위해 태그는 일단 보기 쉽게 바꿔둠.\n","#     # ElementTree의 iter()를 써서 더 좋게 할 수 있는 방법이 있지만\n","#     # 이 짧은 코드에 굳이 그렇게 할 필요성이 없으므로 일단 문자열을 치환하는 방법으로 작성.\n","#     html = html.replace('<em class=\\'green_text\\'>', '<green>') \\\n","#                .replace('<em class=\\'red_text\\'>', '<red>') \\\n","#                .replace('<em class=\\'violet_text\\'>', '<violet>') \\\n","#                .replace('<em class=\\'blue_text\\'>', '<blue>') \\\n","#                .replace('</em>', '<end>')\n","#     items = html.split(' ')\n","#     words = []\n","#     tmp = ''\n","#     for word in items:\n","#         if tmp == '' and word[:1] == '<':\n","#             pos = word.find('>') + 1\n","#             tmp = word[:pos]\n","#         elif tmp != '':\n","#             word = u'{}{}'.format(tmp, word)\n","\n","#         if word[-5:] == '<end>':\n","#             word = word.replace('<end>', '')\n","#             tmp = ''\n","\n","#         words.append(word)\n","\n","#     for word in words:\n","#         check_result = CheckResult.PASSED\n","#         if word[:5] == '<red>':\n","#             check_result = CheckResult.WRONG_SPELLING\n","#             word = word.replace('<red>', '')\n","#         elif word[:7] == '<green>':\n","#             check_result = CheckResult.WRONG_SPACING\n","#             word = word.replace('<green>', '')\n","#         elif word[:8] == '<violet>':\n","#             check_result = CheckResult.AMBIGUOUS\n","#             word = word.replace('<violet>', '')\n","#         elif word[:6] == '<blue>':\n","#             check_result = CheckResult.STATISTICAL_CORRECTION\n","#             word = word.replace('<blue>', '')\n","#         result['words'][word] = check_result\n","\n","#     result = Checked(**result)\n","\n","#     return result"],"metadata":{"id":"rbfQoKcc8voR","executionInfo":{"status":"ok","timestamp":1700284102275,"user_tz":-540,"elapsed":17,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Contents Based Filtering"],"metadata":{"id":"iNqjDvJm_Dsu"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import warnings\n","warnings.filterwarnings(action = 'ignore')\n","\n","from mecab import MeCab\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n","\n","# KoNLPy의 Mecab 형태소 분석기 객체 생성\n","mecab = MeCab()\n","\n","# TF-IDF 벡터화를 위한 객체 생성 및 변환 완료\n","book_tfidf = TfidfVectorizer()\n","book_matrix = book_tfidf.fit_transform(content_df['text'])\n","# 코사인 유사도 계산\n","book_similarity = linear_kernel(book_matrix, book_matrix)\n","\n","# TF-IDF 벡터화를 위한 객체 생성 및 변환 완료\n","feature_tfidf = TfidfVectorizer()\n","feature_matrix = feature_tfidf.fit_transform(content_df['features'])\n","# 코사인 유사도 계산\n","feature_similarity = cosine_similarity(feature_matrix, feature_matrix)"],"metadata":{"id":"_LJU8EQ381tP","executionInfo":{"status":"ok","timestamp":1700287141735,"user_tz":-540,"elapsed":380,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# 맞춤법 검사\n","from hanspell import spell_checker\n","\n","def spell_check(sentence):\n","    return spell_checker.check(sentence).checked"],"metadata":{"id":"us--sdVv9EsM","executionInfo":{"status":"ok","timestamp":1700287142221,"user_tz":-540,"elapsed":4,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# # 원본 데이터 업데이트 시 변경 될 사항들 업데이트\n","\n","# def update_data_and_cosine_sim(new_data, tfidf):\n","#     global book_matrix, book_similarity, feature_matrix, feature_similarity\n","\n","#     # 원본 데이터 업데이트\n","#     tmp = new_data.copy()\n","\n","#     # Content-based-filtering을 위한 하나의 문자열로 만들기\n","#     tmp['text'] = tmp['Keyword'].apply(lambda x: ' '.join(x))\n","#     tmp['features'] = tmp['genres'].apply(lambda x: ' '.join(x)) + ' ' + tmp['mood'].apply(lambda x: ' '.join(x)) + ' ' + tmp['interest'].apply(lambda x: ' '.join(x))\n","\n","#     df = tmp.copy()\n","#     df = tmp.drop(['categoryName', 'description', 'Keyword', 'genres', 'mood', 'interest'], axis = 1)\n","\n","#     # TF-IDF 벡터화 객체에 새로운 데이터 적용 및 변환 완료\n","#     book_matrix = book_tfidf.fit_transform(df['text'])  # 'content'는 실제 텍스트 컬럼명에 맞게 변경해야 합니다.\n","#     # cosine similarity matrix 업데이트\n","#     book_similarity = cosine_similarity(book_matrix)\n","\n","#     # TF-IDF 벡터화\n","#     feature_matrix = feature_tfidf.fit_transform(df['features'])\n","#     # 코사인 유사도 계산\n","#     feature_similarity = cosine_similarity(feature_matrix, feature_matrix)\n","\n","#     return df\n","\n","# # # 사용 예시:\n","# # new_data = data   # update 된 책 데이터를 받아서 consine_based_filtering 데이터로 반환\n","# # df = update_data_and_cosine_sim(new_data, tfidf)\n","# # # df 데이터 저장해두"],"metadata":{"id":"3fSvLBUE9HFb","executionInfo":{"status":"ok","timestamp":1700287142222,"user_tz":-540,"elapsed":4,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# 사용자가 입력한 문장에 대한 책 추천 10권\n","\n","def recommend_books_based_on_sentence(sentence):\n","    # 사용자가 입력한 문장 맞춤법 검사\n","    sentence = spell_checker.check(sentence).checked\n","\n","    # 사용자가 입력한 문장 (형태소로 분리)\n","    user_input_sentence = [\" \".join(mecab.morphs(sentence))]\n","\n","    # 이 문장도 TF-IDF 벡터화를 수행합니다.\n","    user_input_tfidf = book_tfidf.transform(user_input_sentence)\n","\n","    # 코사인 유사도 계산\n","    book_similarity_user_input = cosine_similarity(user_input_tfidf, book_matrix)\n","\n","    # 가장 유사한 10개의 문서 인덱스 찾기\n","    top_10_indexes = np.argsort(-book_similarity_user_input.flatten())[:10]\n","\n","    # 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn13' 컬럼만 가져옵니다.)\n","    similar_books_based_on_user_input = content_df['isbn_id'].iloc[top_10_indexes]\n","\n","    return similar_books_based_on_user_input.tolist()   # list 형태로 반환\n","\n","# sentence = \"오늘은 아침에 제육볶음을 먹고 카페에 들려 초코스무디를 산 후 도서관에 갔다. 도서관에서 밀린 일들을 처리하고 떡볶이 집을 갔지만 떡볶이 집 문이 닫혀있어서 너무나도 슬펐다. 하지만 레드버튼에 놀러가서 친구랑 재미있는 보드게임을 즐겼다. 재미있었다.\"\n","\n","# # 사용 예시:\n","\n","# recommendations = recommend_books_based_on_sentence(sentence)\n","# print(recommendations)"],"metadata":{"id":"LsN_i-MO9MN6","executionInfo":{"status":"ok","timestamp":1700287142757,"user_tz":-540,"elapsed":5,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# isbn13으로 책 제목 추출\n","def get_book_titles_by_isbn(isbn_list):\n","    # isbn_list에 있는 각 isbn에 대응하는 제목 찾기\n","    book_titles = [content_df[content_df['isbn_id'] == isbn]['title'].values[0] for isbn in isbn_list]\n","\n","    return book_titles\n","\n","# # 사용 예시:\n","# isbn_list = recommend_books_based_on_sentence(\"사랑에 대한 이야기\")\n","# book_titles = get_book_titles_by_isbn(isbn_list)    # 리스트 형태로 반환\n","# print(\"\\n\".join(book_titles))"],"metadata":{"id":"5JBYuTUR9OSZ","executionInfo":{"status":"ok","timestamp":1700287142757,"user_tz":-540,"elapsed":4,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# 특정 책(추천받은 책)과 가장 유사한 책 10권\n","\n","def recommend_books_based_on_book(isbn):\n","    # 입력된 isbn에 해당하는 책의 인덱스 찾기\n","    idx = content_df[content_df['isbn_id'] == isbn].index[0]\n","\n","    # 모든 책과의 cosine similarity 값 가져오기\n","    book_similarity_values = book_similarity[idx]\n","\n","    # 가장 유사한 11개의 문서 인덱스 찾기 (자기 자신 포함)\n","    top_11_indexes = np.argsort(-book_similarity_values)[:11]\n","\n","    # 자기 자신 제외하고 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn13' 컬럼만 가져옵니다.)\n","    similar_books_based_on_book = content_df['isbn_id'].iloc[top_11_indexes[1:]]\n","\n","    return similar_books_based_on_book.tolist()\n","\n","# # 사용 예시:\n","# isbn_input = '9791168414471'\n","# similar_isbns = recommend_books_based_on_book(isbn_input)\n","# similar_titles = get_book_titles_by_isbn(similar_isbns)\n","# print(\"\\n\".join(similar_titles))"],"metadata":{"id":"h7Pp0qhl-EYK","executionInfo":{"status":"ok","timestamp":1700287142757,"user_tz":-540,"elapsed":4,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# genres, mood, interest로 책 추천\n","\n","def user_features_recommended_books(genres, mood, interest):\n","    # 사용자 features의 입력을 문자열로 합치기\n","    user_input = ' '.join(genres) + ' ' + ' '.join(mood) + ' ' + ' '.join(interest)\n","\n","    # 사용자의 입력을 벡터화하기\n","    user_input_vector = feature_tfidf.transform([user_input])\n","\n","    # 모든 책에 대한 사용자의 입력과의 유사도를 계산하기\n","    user_feature_book_similarity = linear_kernel(feature_matrix, user_input_vector)\n","\n","    # 유사도에 따라 책들을 정렬하기\n","    sorted_similarity_scores = list(enumerate(user_feature_book_similarity))\n","    sorted_similarity_scores = sorted(sorted_similarity_scores, key=lambda x: x[1], reverse=True)\n","\n","    # 가장 유사한 10개의 책의 인덱스를 가져오기\n","    top10_similar_books = sorted_similarity_scores[0:10]\n","\n","    # 가장 유사한 10개의 책의 인덱스를 이용하여 책의 'isbn13'을 반환\n","    book_indices = [i[0] for i in top10_similar_books]\n","    return content_df['isbn_id'].iloc[book_indices].tolist()\n","\n","# 사용자의 입력에 따라 책을 추천받기\n","# genres = ['시대', '전쟁', '과학']\n","# mood = ['열정', '도전']\n","# interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']\n","\n","# print(user_features_recommended_books(genres, mood, interest))\n"],"metadata":{"id":"VawYOLb5-RWD","executionInfo":{"status":"ok","timestamp":1700287143175,"user_tz":-540,"elapsed":3,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# 사용\n","\n","sentence = input()\n","print(\"\\n\", '='*50, \"\\n\")\n","\n","# 문장에 대해 컨텐츠 기반 필터링\n","isbn_list_by_book = recommend_books_based_on_sentence(sentence) # 리스트 형태로 반환\n","book_titles = get_book_titles_by_isbn(isbn_list_by_book)    # 리스트 형태로 반환\n","print(\"\\n\".join(book_titles))\n","\n","print(\"\\n\", '='*50, \"\\n\")\n","\n","# 뽑은 책에 대해 구한 코사인 유사도로 콘텐츠 기반 필터링\n","similar_isbns = recommend_books_based_on_book(isbn_list_by_book[0])\n","similar_titles = get_book_titles_by_isbn(similar_isbns)\n","print(\"\\n\".join(similar_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34qKvVjD-W_J","executionInfo":{"status":"ok","timestamp":1700287152701,"user_tz":-540,"elapsed":8423,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"2598b193-24dd-440e-9d0d-12e8b986756b"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["이클립스 브라질 여행 가다\n","\n"," ================================================== \n","\n","Go Go 카카오프렌즈 15 : 브라질 - 세계 역사 문화 체험 학습만화\n","오래 준비해온 대답 - 김영하의 시칠리아\n","밤을 걷는 밤 - 나에게 안부를 묻는 시간\n","Go Go 카카오프렌즈 27 : 스위스 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 19 : 한국 2 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 20 : 한국 3 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 17 : 러시아 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 24 : 스웨덴 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 22 : 페루 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 14 : 그리스 - 세계 역사 문화 체험 학습만화\n","\n"," ================================================== \n","\n","Go Go 카카오프렌즈 14 : 그리스 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 17 : 러시아 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 21 : 캐나다 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 16 : 베트남 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 20 : 한국 3 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 19 : 한국 2 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 27 : 스위스 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 24 : 스웨덴 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 22 : 페루 - 세계 역사 문화 체험 학습만화\n","Go Go 카카오프렌즈 23 : 싱가포르\n"]}]},{"cell_type":"code","source":["# 사용자의 입력에 따라 책을 추천받기\n","genres = ['시대', '전쟁', '과학']\n","mood = ['열정', '도전']\n","interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']\n","\n","isbn_list_by_feature = user_features_recommended_books(genres, mood, interest)\n","book_titles = get_book_titles_by_isbn(isbn_list_by_feature)    # 리스트 형태로 반환\n","print(\"\\n\".join(book_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bthfZdLt-vO4","executionInfo":{"status":"ok","timestamp":1700287160475,"user_tz":-540,"elapsed":509,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"904b427f-1562-490b-9501-e9b419850309"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["The Earthian Tales 어션 테일즈 No.1 - alone\n","단 한 사람\n","여름은 오래 그곳에 남아\n","책으로 가는 문 - 이와나미소년문고를 이야기하다\n","2022 제13회 젊은작가상 수상작품집\n","갯마을 차차차 1 - 신하은 대본집\n","갯마을 차차차 2 - 신하은 대본집\n","날아라 슈퍼보드 세트 - 전10권\n","햇빛은 찬란하고 인생은 귀하니까요 - 밀라논나 이야기\n","2023 제14회 젊은작가상 수상작품집\n"]}]},{"cell_type":"markdown","source":["# Collaborative Filtering"],"metadata":{"id":"6wX1FVlH_H-V"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","user_book_rating = collaborative_df.pivot_table(index='nickname', columns='isbn13', values='rating').fillna(0)\n","\n","# 코사인 유사도 계산\n","user_similarity = cosine_similarity(user_book_rating)\n","user_similarity_df = pd.DataFrame(user_similarity, index=user_book_rating.index, columns=user_book_rating.index)"],"metadata":{"id":"JkFThS2m-7qN","executionInfo":{"status":"ok","timestamp":1700287400241,"user_tz":-540,"elapsed":4260,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["def get_user_recommendations(target_user):\n","    # 타겟 사용자와 다른 사용자 간의 유사도\n","    similar_users = user_similarity_df[target_user]\n","\n","    # 유사도 순으로 정렬\n","    similar_users = similar_users.sort_values(ascending=False)\n","\n","    # 타겟 사용자의 평점을 가져옴\n","    user1_ratings = user_book_rating.loc[target_user, :]\n","\n","    # 가장 유사한 사용자의 리스트를 순회 (최대 5명)\n","    for user in similar_users.index[1:6]:\n","        # 각 사용자의 평점을 가져옴\n","        user2_ratings = user_book_rating.loc[user, :]\n","\n","        # 타겟 사용자가 평가하지 않은 책 중, 평점이 3 이상인 책만 추천\n","        recommendations = user2_ratings[(user1_ratings == 0) & (user2_ratings >= 3)].sort_values(ascending=False)\n","\n","        # 만약 추천할 책이 있다면 반환\n","        if not recommendations.empty:\n","            return recommendations\n","\n","    # 모든 사용자를 순회했음에도 추천할 책이 없다면 메시지 반환\n","    return \"추천할 만한 책이 없습니다.\"\n","\n","print(get_user_recommendations('글월마야'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PU6qZp-2AAJU","executionInfo":{"status":"ok","timestamp":1700287651685,"user_tz":-540,"elapsed":346,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"cc018772-d226-4c8a-df0d-864872eb44b1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["isbn13\n","9791139710960    5.0\n","Name: 붉은돼지, dtype: float64\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"v9_EI4bEACrl"},"execution_count":null,"outputs":[]}]}