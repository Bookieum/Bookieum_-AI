{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["3VGTzmGjgzNh"],"authorship_tag":"ABX9TyMUoRmqrpgPLAwuCi0//YX+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBel-YaP2bP_","executionInfo":{"status":"ok","timestamp":1700312775703,"user_tz":-540,"elapsed":19373,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"7eb92705-3984-4116-fbb0-039c5d15e7d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# 구글 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import joblib\n","path = '/content/drive/MyDrive/해커톤/data/data.pkl'\n","data = joblib.load(path)"],"metadata":{"id":"zPUa_h9M21XA","executionInfo":{"status":"ok","timestamp":1700319800977,"user_tz":-540,"elapsed":306,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["import joblib\n","path = '/content/drive/MyDrive/해커톤/data/cosine_data.pkl'\n","content_df = joblib.load(path)"],"metadata":{"id":"PRl5y15y5cgI","executionInfo":{"status":"ok","timestamp":1700312878160,"user_tz":-540,"elapsed":8,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import joblib\n","\n","# pickle 파일 불러오기\n","collaborative_df = joblib.load('/content/drive/MyDrive/해커톤/data/collaborative_data.pkl')"],"metadata":{"id":"T1wJacCo725Y","executionInfo":{"status":"ok","timestamp":1700321830161,"user_tz":-540,"elapsed":291,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["print(data.shape)\n","print(content_df.shape)\n","print(collaborative_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVHKcuuL8cT_","executionInfo":{"status":"ok","timestamp":1700312878160,"user_tz":-540,"elapsed":6,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"88409384-22b8-4593-cf28-e2fbcb0a80d9"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(534, 15)\n","(534, 5)\n","(15510, 5)\n"]}]},{"cell_type":"code","source":["# from mecab import MeCab 설치\n","!pip install konlpy pandas seaborn gensim wordcloud python-mecab-ko wget svgling"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"45OMppUn8hdv","executionInfo":{"status":"ok","timestamp":1700312892004,"user_tz":-540,"elapsed":12601,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"ddec6def-06a0-48c3-873b-7500cef1058c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.2)\n","Requirement already satisfied: python-mecab-ko in /usr/local/lib/python3.10/dist-packages (1.3.3)\n","Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n","Requirement already satisfied: svgling in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.4.1)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (9.4.0)\n","Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.10/dist-packages (from python-mecab-ko) (2.1.1.post2)\n","Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from svgling) (1.4.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"]}]},{"cell_type":"markdown","source":["## Py-Hanspell 사용시 주의\n","* 1. pip설치\n","* 2. 예시 실행 → 에러\n","* 3. 에러 내용중 pyhaspell.py? 같은걸로 시작하는 파일 아래 주석 쳐진 코드로 변경! (완전 다)\n","* 4. 런타임 다시 시작\n","* 5. 런타임 다시 시작 후 pip는 다시 다운 안받도록 조심!"],"metadata":{"id":"cPeiVhxLJ0Mj"}},{"cell_type":"code","source":["# # Py-Hanspell\n","# # 한국어 전처리 패키지\n","# # 네이버 한글 맞춤법 검사기를 바탕으로 만들어진 패키지로써 맞춤법을 고친 문장을 반환\n","# # 네이버 맞춤법 검사기 API를 사용하는 것이므로 500자 이상은 불가능..\n","\n","# !pip install git+https://github.com/ssut/py-hanspell"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrBXxfMf8txq","executionInfo":{"status":"ok","timestamp":1700312831296,"user_tz":-540,"elapsed":19990,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"2ac2188d-3161-4242-f302-1fff30fc837f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/ssut/py-hanspell\n","  Cloning https://github.com/ssut/py-hanspell to /tmp/pip-req-build-3wv_bw5n\n","  Running command git clone --filter=blob:none --quiet https://github.com/ssut/py-hanspell /tmp/pip-req-build-3wv_bw5n\n","  Resolved https://github.com/ssut/py-hanspell to commit fdc6ca50c19f1c85971437a072d89d4e5ce024b8\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from py-hanspell==1.1) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->py-hanspell==1.1) (2023.7.22)\n","Building wheels for collected packages: py-hanspell\n","  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4811 sha256=a6e28cf6ec42582c3f46a4ad5c45f5f462ba500935522fafc06a0b0d8c04766c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-jjj5ks7s/wheels/8a/a2/42/dd59a6ea430825c9ca823f2012a3f02cc7b272eff1618e6baf\n","Successfully built py-hanspell\n","Installing collected packages: py-hanspell\n","Successfully installed py-hanspell-1.1\n"]}]},{"cell_type":"code","source":["# # 예시\n","# sentence = '아이스크림 먹고 싶다.'\n","# sentence = spell_checker.check(sentence).checked\n","# print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfIIe79HhX02","executionInfo":{"status":"ok","timestamp":1700312895137,"user_tz":-540,"elapsed":2649,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"23b605ac-c4f7-4dc1-a65a-eacc1b841fc7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["아이스크림 먹고 싶다.\n"]}]},{"cell_type":"code","source":["# # -*- coding: utf-8 -*-\n","# \"\"\"\n","# Python용 한글 맞춤법 검사 모듈\n","# \"\"\"\n","\n","# import requests\n","# import json\n","# import time\n","# import sys\n","# import re\n","# from cachetools import TTLCache\n","# from urllib import parse\n","# from collections import OrderedDict\n","# import xml.etree.ElementTree as ET\n","\n","# from . import __version__\n","# from .response import Checked\n","# from .constants import base_url\n","# from .constants import CheckResult\n","\n","# _agent = requests.Session()\n","# PY3 = sys.version_info[0] == 3\n","# cache = TTLCache(maxsize = 10, ttl = 3600)\n","\n","# def read_token():\n","#     try:\n","#         TOKEN = cache.get('PASSPORT_TOKEN')\n","#         return TOKEN\n","#     except KeyError:\n","#         return None\n","\n","# def update_token(agent):\n","\n","#     html = agent.get(url='https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=맞춤법검사기')\n","\n","#     match = re.search('passportKey=([a-zA-Z0-9]+)', html.text)\n","#     if match is not None:\n","#         TOKEN = parse.unquote(match.group(1))\n","#         cache['PASSPORT_TOKEN'] = TOKEN\n","#     return TOKEN\n","\n","# def _remove_tags(text):\n","#     text = u'<content>{}</content>'.format(text).replace('<br>','')\n","#     if not PY3:\n","#         text = text.encode('utf-8')\n","\n","#     result = ''.join(ET.fromstring(text).itertext())\n","\n","#     return result\n","\n","# def get_response(TOKEN, text):\n","\n","#     if TOKEN is None:\n","#         TOKEN = update_token(_agent)\n","\n","#     payload = {\n","#         'passportKey' : TOKEN,\n","#         'q': text,\n","#         'color_blindness': 0\n","#     }\n","\n","#     headers = {\n","#         'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n","#         'referer': 'https://search.naver.com/',\n","#     }\n","\n","#     r = _agent.get(base_url, params=payload, headers=headers)\n","#     data = json.loads(r.text)\n","\n","#     if 'error' in data['message'] :\n","#         r = get_response(update_token(_agent), text)\n","\n","#     return r\n","\n","\n","# def check(text):\n","#     \"\"\"\n","#     매개변수로 입력받은 한글 문장의 맞춤법을 체크합니다.\n","#     \"\"\"\n","#     if isinstance(text, list):\n","#         result = []\n","#         for item in text:\n","#             checked = check(item)\n","#             result.append(checked)\n","#         return result\n","\n","#     # 최대 500자까지 가능.\n","#     if len(text) > 500:\n","#         return Checked(result=False)\n","\n","#     start_time = time.time()\n","#     r = get_response(read_token(), text)\n","#     passed_time = time.time() - start_time\n","\n","#     data = json.loads(r.text)\n","#     html = data['message']['result']['html']\n","#     result = {\n","#         'result': True,\n","#         'original': text,\n","#         'checked': _remove_tags(html),\n","#         'errors': data['message']['result']['errata_count'],\n","#         'time': passed_time,\n","#         'words': OrderedDict(),\n","#     }\n","\n","#     # 띄어쓰기로 구분하기 위해 태그는 일단 보기 쉽게 바꿔둠.\n","#     # ElementTree의 iter()를 써서 더 좋게 할 수 있는 방법이 있지만\n","#     # 이 짧은 코드에 굳이 그렇게 할 필요성이 없으므로 일단 문자열을 치환하는 방법으로 작성.\n","#     html = html.replace('<em class=\\'green_text\\'>', '<green>') \\\n","#                .replace('<em class=\\'red_text\\'>', '<red>') \\\n","#                .replace('<em class=\\'violet_text\\'>', '<violet>') \\\n","#                .replace('<em class=\\'blue_text\\'>', '<blue>') \\\n","#                .replace('</em>', '<end>')\n","#     items = html.split(' ')\n","#     words = []\n","#     tmp = ''\n","#     for word in items:\n","#         if tmp == '' and word[:1] == '<':\n","#             pos = word.find('>') + 1\n","#             tmp = word[:pos]\n","#         elif tmp != '':\n","#             word = u'{}{}'.format(tmp, word)\n","\n","#         if word[-5:] == '<end>':\n","#             word = word.replace('<end>', '')\n","#             tmp = ''\n","\n","#         words.append(word)\n","\n","#     for word in words:\n","#         check_result = CheckResult.PASSED\n","#         if word[:5] == '<red>':\n","#             check_result = CheckResult.WRONG_SPELLING\n","#             word = word.replace('<red>', '')\n","#         elif word[:7] == '<green>':\n","#             check_result = CheckResult.WRONG_SPACING\n","#             word = word.replace('<green>', '')\n","#         elif word[:8] == '<violet>':\n","#             check_result = CheckResult.AMBIGUOUS\n","#             word = word.replace('<violet>', '')\n","#         elif word[:6] == '<blue>':\n","#             check_result = CheckResult.STATISTICAL_CORRECTION\n","#             word = word.replace('<blue>', '')\n","#         result['words'][word] = check_result\n","\n","#     result = Checked(**result)\n","\n","#     return result"],"metadata":{"id":"rbfQoKcc8voR","executionInfo":{"status":"ok","timestamp":1700312831297,"user_tz":-540,"elapsed":18,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Contents Based Filtering"],"metadata":{"id":"iNqjDvJm_Dsu"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import warnings\n","warnings.filterwarnings(action = 'ignore')\n","\n","from mecab import MeCab\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n","\n","# KoNLPy의 Mecab 형태소 분석기 객체 생성\n","mecab = MeCab()\n","\n","# TF-IDF 벡터화를 위한 객체 생성 및 변환 완료\n","book_tfidf = TfidfVectorizer()\n","book_matrix = book_tfidf.fit_transform(content_df['text'])\n","# 코사인 유사도 계산\n","book_similarity = linear_kernel(book_matrix, book_matrix)\n","\n","# TF-IDF 벡터화를 위한 객체 생성 및 변환 완료\n","feature_tfidf = TfidfVectorizer()\n","feature_matrix = feature_tfidf.fit_transform(content_df['features'])\n","# 코사인 유사도 계산\n","feature_similarity = cosine_similarity(feature_matrix, feature_matrix)"],"metadata":{"id":"_LJU8EQ381tP","executionInfo":{"status":"ok","timestamp":1700312892490,"user_tz":-540,"elapsed":490,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 맞춤법 검사\n","from hanspell import spell_checker\n","\n","def spell_check(sentence):\n","    return spell_checker.check(sentence).checked"],"metadata":{"id":"us--sdVv9EsM","executionInfo":{"status":"ok","timestamp":1700312892490,"user_tz":-540,"elapsed":3,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# # 원본 데이터 업데이트 시 변경 될 사항들 업데이트\n","\n","# def update_data_and_cosine_sim(new_data, tfidf):\n","#     global book_matrix, book_similarity, feature_matrix, feature_similarity\n","\n","#     # 원본 데이터 업데이트\n","#     tmp = new_data.copy()\n","\n","#     # Content-based-filtering을 위한 하나의 문자열로 만들기\n","#     tmp['text'] = tmp['Keyword'].apply(lambda x: ' '.join(x))\n","#     tmp['features'] = tmp['genres'].apply(lambda x: ' '.join(x)) + ' ' + tmp['mood'].apply(lambda x: ' '.join(x)) + ' ' + tmp['interest'].apply(lambda x: ' '.join(x))\n","\n","#     df = tmp.copy()\n","#     df = tmp.drop(['categoryName', 'description', 'Keyword', 'genres', 'mood', 'interest'], axis = 1)\n","\n","#     # TF-IDF 벡터화 객체에 새로운 데이터 적용 및 변환 완료\n","#     book_matrix = book_tfidf.fit_transform(df['text'])  # 'content'는 실제 텍스트 컬럼명에 맞게 변경해야 합니다.\n","#     # cosine similarity matrix 업데이트\n","#     book_similarity = cosine_similarity(book_matrix)\n","\n","#     # TF-IDF 벡터화\n","#     feature_matrix = feature_tfidf.fit_transform(df['features'])\n","#     # 코사인 유사도 계산\n","#     feature_similarity = cosine_similarity(feature_matrix, feature_matrix)\n","\n","#     return df\n","\n","# # # 사용 예시:\n","# # new_data = data   # update 된 책 데이터를 받아서 consine_based_filtering 데이터로 반환\n","# # df = update_data_and_cosine_sim(new_data, tfidf)\n","# # # df 데이터 저장해두"],"metadata":{"id":"3fSvLBUE9HFb","executionInfo":{"status":"ok","timestamp":1700312451711,"user_tz":-540,"elapsed":16,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## 사용자가 적은 문장 기반 가장 유사한 책 10권\n","* 사용자의 감정점수에 따라 sorting"],"metadata":{"id":"NKWaRnRRfbFH"}},{"cell_type":"code","source":["# 사용자가 입력한 문장에 대한 책 추천 10권\n","\n","def recommend_books_based_on_sentence(sentence, user_read):\n","    # 사용자가 입력한 문장 맞춤법 검사\n","    sentence = spell_checker.check(sentence).checked\n","\n","    # 사용자가 입력한 문장 (형태소로 분리)\n","    user_input_sentence = [\" \".join(mecab.morphs(sentence))]\n","\n","    # 이 문장도 TF-IDF 벡터화를 수행합니다.\n","    user_input_tfidf = book_tfidf.transform(user_input_sentence)\n","\n","    # 코사인 유사도 계산\n","    book_similarity_user_input = cosine_similarity(user_input_tfidf, book_matrix)\n","\n","    # 가장 유사한 책들의 인덱스 찾기\n","    similar_book_indexes = np.argsort(-book_similarity_user_input.flatten())\n","\n","    # 사용자가 이미 읽은 책 제외\n","    similar_book_indexes = [idx for idx in similar_book_indexes if content_df['isbn_id'].iloc[idx] not in user_read]\n","\n","    # 가장 유사한 10개의 문서 인덱스 가져오기\n","    top_10_indexes = similar_book_indexes[:10]\n","\n","    # 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn_id' 컬럼만 가져옵니다.)\n","    similar_books_based_on_user_input = content_df['isbn_id'].iloc[top_10_indexes]\n","\n","    return similar_books_based_on_user_input.tolist()   # list 형태로 반환\n","\n","\n","# sentence = \"오늘은 아침에 제육볶음을 먹고 카페에 들려 초코스무디를 산 후 도서관에 갔다. 도서관에서 밀린 일들을 처리하고 떡볶이 집을 갔지만 떡볶이 집 문이 닫혀있어서 너무나도 슬펐다. 하지만 레드버튼에 놀러가서 친구랑 재미있는 보드게임을 즐겼다. 재미있었다.\"\n","\n","# # 사용 예시:\n","\n","# recommendations = recommend_books_based_on_sentence(sentence, user_read)\n","# print(recommendations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dO7s-aGDuwyg","executionInfo":{"status":"ok","timestamp":1700317081672,"user_tz":-540,"elapsed":759,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"e64b3ddb-f5d5-4033-856d-dba1b291252c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["['9788989863786', '9791190758185', '9788934972204', '9791136279248', '9791167740175', '9791192186214', '9788926718766', '9788937473098', '9788925588902', '9788949108308']\n"]}]},{"cell_type":"code","source":["# def recommend_books_based_on_sentence(sentence, emotion):\n","#     # 사용자가 입력한 문장 맞춤법 검사\n","#     sentence = spell_checker.check(sentence).checked\n","\n","#     # 사용자가 입력한 문장 (형태소로 분리)\n","#     user_input_sentence = [\" \".join(mecab.morphs(sentence))]\n","\n","#     # 이 문장도 TF-IDF 벡터화를 수행합니다.\n","#     user_input_tfidf = book_tfidf.transform(user_input_sentence)\n","\n","#     # 코사인 유사도 계산\n","#     book_similarity_user_input = cosine_similarity(user_input_tfidf, book_matrix)\n","\n","#     # 가장 유사한 10개의 문서 인덱스 찾기\n","#     top_10_indexes = np.argsort(-book_similarity_user_input.flatten())[:10]\n","\n","#     # 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn_id' 컬럼만 가져옵니다.)\n","#     similar_books_based_on_user_input = content_df['isbn_id'].iloc[top_10_indexes].tolist()\n","\n","#     # isbn_id와 emotion_score를 DataFrame으로 가져옵니다.\n","#     similar_books_df = content_df[content_df['isbn_id'].isin(similar_books_based_on_user_input)][['isbn_id', 'emotion_score']]\n","\n","#     # 사용자가 입력한 emotion과의 차이를 계산합니다.\n","#     similar_books_df['emotion_diff'] = abs(similar_books_df['emotion_score'] - emotion)\n","\n","#     # emotion_diff를 기준으로 오름차순 정렬합니다.\n","#     similar_books_df = similar_books_df.sort_values('emotion_diff')\n","\n","#     return similar_books_df['isbn_id'].tolist()  # emotion_diff가 가장 작은 순서대로 정렬된 isbn_id list를 반환합니다.\n","\n","\n","# # sentence = \"오늘은 아침에 제육볶음을 먹고 카페에 들려 초코스무디를 산 후 도서관에 갔다. 도서관에서 밀린 일들을 처리하고 떡볶이 집을 갔지만 떡볶이 집 문이 닫혀있어서 너무나도 슬펐다. 하지만 레드버튼에 놀러가서 친구랑 재미있는 보드게임을 즐겼다. 재미있었다.\"\n","\n","# # # 사용 예시:\n","\n","# # recommendations = recommend_books_based_on_sentence(sentence, 0.5)\n","# # print(recommendations)"],"metadata":{"id":"6Vi7yzo5ajCW","executionInfo":{"status":"ok","timestamp":1700312920647,"user_tz":-540,"elapsed":457,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## 반환받은 isbn13으로 책 제목 추출"],"metadata":{"id":"u3RTrFZ2fl3J"}},{"cell_type":"code","source":["# isbn13으로 책 제목 추출\n","def get_book_titles_by_isbn(isbn_list):\n","    # isbn_list에 있는 각 isbn에 대응하는 제목 찾기\n","    book_titles = [content_df[content_df['isbn_id'] == isbn]['title'].values[0] for isbn in isbn_list]\n","\n","    return book_titles\n","\n","# # 사용 예시:\n","# isbn_list = recommend_books_based_on_sentence(\"사랑에 대한 이야기\")\n","# book_titles = get_book_titles_by_isbn(isbn_list)    # 리스트 형태로 반환\n","# print(\"\\n\".join(book_titles))"],"metadata":{"id":"5JBYuTUR9OSZ","executionInfo":{"status":"ok","timestamp":1700312921087,"user_tz":-540,"elapsed":2,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## 하나의 책을 기반으로 유사한 책 추천 10권\n","* 사용자 감정점수에 따라 sorting"],"metadata":{"id":"OkJl8JClfwFy"}},{"cell_type":"code","source":["# 특정 책(추천받은 책)과 가장 유사한 책 10권\n","\n","def recommend_books_based_on_book(isbn, user_read, num_books=10):\n","    # 입력된 isbn에 해당하는 책의 인덱스 찾기\n","    idx = content_df[content_df['isbn_id'] == isbn].index[0]\n","\n","    # 모든 책과의 cosine similarity 값 가져오기\n","    book_similarity_values = book_similarity[idx]\n","\n","    # 가장 유사한 책들의 인덱스 찾기\n","    similar_book_indexes = np.argsort(-book_similarity_values)\n","\n","    # 사용자가 이미 읽은 책 제외\n","    similar_book_indexes = [idx for idx in similar_book_indexes if content_df['isbn_id'].iloc[idx] not in user_read]\n","\n","    # 가장 유사한 num_books개의 문서 인덱스 가져오기\n","    top_indexes = similar_book_indexes[:num_books]\n","\n","    # 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn_id' 컬럼만 가져옵니다.)\n","    similar_books_based_on_book = content_df['isbn_id'].iloc[top_indexes]\n","\n","    return similar_books_based_on_book.tolist()   # list 형태로 반환\n","\n","\n","# # 사용 예시:\n","# isbn_input = '9791198173898'\n","# similar_isbns = recommend_books_based_on_book(isbn_input, user_read)\n","# similar_titles = get_book_titles_by_isbn(similar_isbns)\n","# print(\"\\n\".join(similar_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCH0MwMzusuA","executionInfo":{"status":"ok","timestamp":1700320898200,"user_tz":-540,"elapsed":6,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"4ab9312b-92a3-423b-9d7d-eff436f9c645"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["비가 오면 열리는 상점\n","역행자 확장판 - 돈·시간·운명으로부터 완전한 자유를 얻는 7단계 인생 공략집\n","반지의 제왕 일러스트 특별판 - 반지 원정대 + 두 개의 탑 + 왕의 귀환\n","문명 2\n","문명 1\n","저주토끼 (리커버)\n","생각한다는 착각 - 뇌과학과 인지심리학으로 풀어낸 마음의 재해석\n","365일 명화 일력 (스프링) - 하루의 시작이 좋아지는 그림의 힘\n","기적의 자세요정 - 무너진 자세를 바로 세우는\n","블라인드 1 - 초호화 크루즈 살인사건\n"]}]},{"cell_type":"code","source":["# def recommend_books_based_on_book(isbn, emotion):\n","#     # 입력된 isbn에 해당하는 책의 인덱스 찾기\n","#     idx = content_df[content_df['isbn_id'] == isbn].index[0]\n","\n","#     # 모든 책과의 cosine similarity 값 가져오기\n","#     book_similarity_values = book_similarity[idx]\n","\n","#     # 가장 유사한 11개의 문서 인덱스 찾기 (자기 자신 포함)\n","#     top_11_indexes = np.argsort(-book_similarity_values)[:11]\n","\n","#     # 자기 자신 제외하고 원본 데이터프레임에서 해당하는 행 가져오기 (여기서는 'isbn_id'와 'emotion_score' 컬럼을 가져옵니다.)\n","#     similar_books_based_on_book = content_df[['isbn_id', 'emotion_score']].iloc[top_11_indexes[1:]]\n","\n","#     # 사용자가 입력한 emotion과의 차이를 계산합니다.\n","#     similar_books_based_on_book['emotion_diff'] = abs(similar_books_based_on_book['emotion_score'] - emotion)\n","\n","#     # emotion_diff를 기준으로 오름차순 정렬합니다.\n","#     similar_books_based_on_book = similar_books_based_on_book.sort_values('emotion_diff')\n","\n","#     return similar_books_based_on_book['isbn_id'].tolist()  # emotion_diff가 가장 작은 순서대로 정렬된 isbn_id list를 반환합니다.\n","\n","# # # 사용 예시:\n","# # isbn_input = '9791198173898'\n","# # similar_isbns = recommend_books_based_on_book(isbn_input, 0.5)\n","# # similar_titles = get_book_titles_by_isbn(similar_isbns)\n","# # print(\"\\n\".join(similar_titles))"],"metadata":{"id":"JzNLGe3Kb1J1","executionInfo":{"status":"ok","timestamp":1700312922689,"user_tz":-540,"elapsed":2,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## 회원가입 시 사용자의 선호장르 기반으로 책 추천 10권\n","* 사용자의 감정점수에 따라 sorting"],"metadata":{"id":"rsMDbXeDgmT8"}},{"cell_type":"code","source":["# genres, mood, interest로 책 추천\n","\n","def user_features_recommended_books(genres, mood, interest, user_read):\n","    # 사용자 features의 입력을 문자열로 합치기\n","    user_input = ' '.join(genres) + ' ' + ' '.join(mood) + ' ' + ' '.join(interest)\n","\n","    # 사용자의 입력을 벡터화하기\n","    user_input_vector = feature_tfidf.transform([user_input])\n","\n","    # 모든 책에 대한 사용자의 입력과의 유사도를 계산하기\n","    user_feature_book_similarity = linear_kernel(feature_matrix, user_input_vector)\n","\n","    # 유사도에 따라 책들을 정렬하기\n","    sorted_similarity_scores = list(enumerate(user_feature_book_similarity))\n","    sorted_similarity_scores = sorted(sorted_similarity_scores, key=lambda x: x[1], reverse=True)\n","\n","    # 사용자가 이미 읽은 책 제외\n","    sorted_similarity_scores = [score for score in sorted_similarity_scores if content_df['isbn_id'].iloc[score[0]] not in user_read]\n","\n","    # 가장 유사한 10개의 책의 인덱스를 가져오기\n","    top10_similar_books = sorted_similarity_scores[0:10]\n","\n","    # 가장 유사한 10개의 책의 인덱스를 이용하여 책의 'isbn_id'를 반환\n","    book_indices = [i[0] for i in top10_similar_books]\n","    return content_df['isbn_id'].iloc[book_indices].tolist()   # list 형태로 반환\n","\n","\n","# # 사용자의 입력에 따라 책을 추천받기\n","# genres = ['시대', '전쟁', '과학']\n","# mood = ['열정', '도전']\n","# interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']\n","\n","# print(user_features_recommended_books(genres, mood, interest, user_read))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkst2JHOupD0","executionInfo":{"status":"ok","timestamp":1700317481714,"user_tz":-540,"elapsed":6,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"1eb8ac52-caf4-4214-e2fd-779acecfa262"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["['9791160405750', '9788934972204', '9788988964637', '9788954685887', '9791168030046', '9791168030053', '9791167780065', '9788934985051', '9788954691741', '9791197025600']\n"]}]},{"cell_type":"code","source":["# def user_features_recommended_books(genres, mood, interest, emotion):\n","#     # 사용자 features의 입력을 문자열로 합치기\n","#     user_input = ' '.join(genres) + ' ' + ' '.join(mood) + ' ' + ' '.join(interest)\n","\n","#     # 사용자의 입력을 벡터화하기\n","#     user_input_vector = feature_tfidf.transform([user_input])\n","\n","#     # 모든 책에 대한 사용자의 입력과의 유사도를 계산하기\n","#     user_feature_book_similarity = linear_kernel(feature_matrix, user_input_vector)\n","\n","#     # 유사도에 따라 책들을 정렬하기\n","#     sorted_similarity_scores = list(enumerate(user_feature_book_similarity))\n","#     sorted_similarity_scores = sorted(sorted_similarity_scores, key=lambda x: x[1], reverse=True)\n","\n","#     # 가장 유사한 10개의 책의 인덱스를 가져오기\n","#     top10_similar_books = sorted_similarity_scores[0:10]\n","\n","#     # 가장 유사한 10개의 책의 인덱스를 이용하여 책의 'isbn_id'와 'emotion_score'를 가져오기\n","#     book_indices = [i[0] for i in top10_similar_books]\n","#     similar_books_based_on_user_features = content_df[['isbn_id', 'emotion_score']].iloc[book_indices]\n","\n","#     # 사용자가 입력한 emotion과의 차이를 계산합니다.\n","#     similar_books_based_on_user_features['emotion_diff'] = abs(similar_books_based_on_user_features['emotion_score'] - emotion)\n","\n","#     # emotion_diff를 기준으로 오름차순 정렬합니다.\n","#     similar_books_based_on_user_features = similar_books_based_on_user_features.sort_values('emotion_diff')\n","\n","#     return similar_books_based_on_user_features['isbn_id'].tolist()  # emotion_diff가 가장 작은 순서대로 정렬된 isbn_id list를 반환합니다.\n","\n","\n","# # # 사용자의 입력에 따라 책을 추천받기\n","# # genres = ['시대', '전쟁', '과학']\n","# # mood = ['열정', '도전']\n","# # interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']\n","\n","# # print(user_features_recommended_books(genres, mood, interest, 0.5))"],"metadata":{"id":"vAhHynkrcbnU","executionInfo":{"status":"ok","timestamp":1700312924326,"user_tz":-540,"elapsed":411,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## 사용 예시"],"metadata":{"id":"3VGTzmGjgzNh"}},{"cell_type":"code","source":["# 사용\n","\n","emotion = 0.5\n","sentence = input()\n","user_read = ['9772799628000', '9791198375308']  # 사용자가 읽었던 책 isbn13\n","\n","print(\"\\n\", '='*50, \"\\n\")\n","\n","# 문장에 대해 컨텐츠 기반 필터링\n","isbn_list_by_book = recommend_books_based_on_sentence(sentence, user_read) # 리스트 형태로 반환\n","book_titles = get_book_titles_by_isbn(isbn_list_by_book)    # 리스트 형태로 반환\n","print(\"\\n\".join(book_titles))\n","\n","print(\"\\n\", '='*50, \"\\n\")\n","\n","# 뽑은 책에 대해 구한 코사인 유사도로 콘텐츠 기반 필터링\n","similar_isbns = recommend_books_based_on_book(isbn_list_by_book[0], user_read)\n","similar_titles = get_book_titles_by_isbn(similar_isbns)\n","print(\"\\n\".join(similar_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34qKvVjD-W_J","executionInfo":{"status":"ok","timestamp":1700317070244,"user_tz":-540,"elapsed":4922,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"8ebcf739-5d44-4478-c50a-34ca8a50bf80"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["아이스크림 먹고싶다\n","\n"," ================================================== \n","\n","화산귀환 1~2 세트 - 전2권 (윷놀이 세트 + 미니 윷놀이 말판 + 엽서 2종 포함 한정판)\n","매일 이곳이 좋아집니다 - 낯선 곳에서 나 혼자 쌓아올린 괜찮은 하루하루\n","하이큐!! 10th 크로니클 (한정판) - 아크릴 피규어 30개 + 추억의 포토카드 120장 + 팀 오피셜 핀 배지 2개\n","바니타스의 수기 10 (특별 소책자 포함 특장판)\n","내가 죽기로 결심한 것은 3\n","156층 나무 집\n","스킵과 로퍼 6 - 시프트코믹스\n","스파이 패밀리 9\n","김용균, 김용균들 - 싸울 때 제대로 살아갈 수 있는 사람들\n","세이노의 가르침\n","\n"," ================================================== \n","\n","말하기를 말하기 - 제대로 목소리를 내기 위하여\n","놓지 마 과학! 13 - 정신이 미세 먼지에 정신 놓다\n","2030 축의 전환 - 새로운 부와 힘을 탄생시킬 8가지 거대한 물결\n","눈아이\n","블랙 쇼맨과 이름 없는 마을의 살인\n","이수정 이다혜의 범죄 영화 프로파일\n","인사반파자구계통 박스 세트 - 전3권 (스티커 + 엽서 세트(4종) + 마스킹테이프 + L홀더 + 떡메모지 + 일러스트 족자봉)\n","사이토 히토리의 1퍼센트 부자의 법칙 - 반드시 성공하는 일천 번의 법칙\n","세븐 테크 - 3년 후 당신의 미래를 바꿀 7가지 기술\n","도원암귀 2 - S코믹스\n"]}]},{"cell_type":"code","source":["# 사용자의 입력에 따라 책을 추천받기\n","genres = ['시대', '전쟁', '과학']\n","mood = ['열정', '도전']\n","interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']\n","\n","isbn_list_by_feature = user_features_recommended_books(genres, mood, interest, emotion)\n","book_titles = get_book_titles_by_isbn(isbn_list_by_feature)    # 리스트 형태로 반환\n","print(\"\\n\".join(book_titles))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bthfZdLt-vO4","executionInfo":{"status":"ok","timestamp":1700313045849,"user_tz":-540,"elapsed":552,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"0012f0e7-6563-4e28-c69a-7c27e4f66d36"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["The Earthian Tales 어션 테일즈 No.1 - alone\n","단 한 사람\n","여름은 오래 그곳에 남아\n","날아라 슈퍼보드 세트 - 전10권\n","2023 제14회 젊은작가상 수상작품집\n","2022 제13회 젊은작가상 수상작품집\n","햇빛은 찬란하고 인생은 귀하니까요 - 밀라논나 이야기\n","책으로 가는 문 - 이와나미소년문고를 이야기하다\n","갯마을 차차차 1 - 신하은 대본집\n","갯마을 차차차 2 - 신하은 대본집\n"]}]},{"cell_type":"markdown","source":["# Collaborative Filtering"],"metadata":{"id":"6wX1FVlH_H-V"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","user_book_rating = collaborative_df.pivot_table(index='nickname', columns='isbn_id', values='rating').fillna(0)\n","\n","# 코사인 유사도 계산\n","user_similarity = cosine_similarity(user_book_rating)\n","user_similarity_df = pd.DataFrame(user_similarity, index=user_book_rating.index, columns=user_book_rating.index)"],"metadata":{"id":"JkFThS2m-7qN","executionInfo":{"status":"ok","timestamp":1700322870882,"user_tz":-540,"elapsed":4663,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["# def get_user_recommendations(target_user):\n","#     # 타겟 사용자와 다른 사용자 간의 유사도\n","#     similar_users = user_similarity_df[target_user]\n","\n","#     # 유사도 순으로 정렬\n","#     similar_users = similar_users.sort_values(ascending=False)\n","\n","#     # 타겟 사용자의 평점을 가져옴\n","#     user1_ratings = user_book_rating.loc[target_user, :]\n","\n","#     # 가장 유사한 사용자의 리스트를 순회 (최대 5명)\n","#     for user in similar_users.index[1:6]:\n","#         # 각 사용자의 평점을 가져옴\n","#         user2_ratings = user_book_rating.loc[user, :]\n","\n","#         # 타겟 사용자가 평가하지 않은 책 중, 평점이 3 이상인 책만 추천\n","#         recommendations = user2_ratings[(user1_ratings == 0) & (user2_ratings >= 3)].sort_values(ascending=False)\n","\n","#         # 만약 추천할 책이 있다면 반환\n","#         if not recommendations.empty:\n","#             return recommendations\n","\n","#     # 모든 사용자를 순회했음에도 추천할 책이 없다면 메시지 반환\n","#     return \"추천할 만한 책이 없습니다.\"\n","\n","# print(get_user_recommendations('글월마야'))"],"metadata":{"id":"PU6qZp-2AAJU","executionInfo":{"status":"ok","timestamp":1700322873993,"user_tz":-540,"elapsed":313,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":103,"outputs":[]},{"cell_type":"code","source":["def get_user_recommendations(target_user):\n","    similar_users = user_similarity_df[target_user]\n","\n","    # 유사도 순으로 정렬\n","    similar_users = similar_users.sort_values(ascending=False)\n","\n","    # 타겟 사용자의 평점을 가져옴\n","    user1_ratings = user_book_rating.loc[target_user, :]\n","\n","    # 가장 유사한 사용자의 리스트를 순회\n","    for user in similar_users.index[1:6]:\n","        # 각 사용자의 평점을 가져옴\n","        user2_ratings = user_book_rating.loc[user, :]\n","\n","        # 타겟 사용자가 평가하지 않은 책 중, 평점이 3 이상인 책만 추천\n","        recommendations = user2_ratings[(user1_ratings == 0) & (user2_ratings >= 3)]\n","\n","        # 만약 추천할 책이 있다면 반환\n","        if not recommendations.empty:\n","            # Series를 list로 변환, 평점을 제외하고 책의 ID만 반환\n","            return [item[0] for item in recommendations.sort_values(ascending=False).items()][:10]\n","\n","    # 모든 사용자를 순회했음에도 추천할 책이 없다면 빈 리스트 반환\n","    return []\n","\n","# print(get_user_recommendations('글월마야'))"],"metadata":{"id":"v9_EI4bEACrl","executionInfo":{"status":"ok","timestamp":1700322875045,"user_tz":-540,"elapsed":3,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"RrYUt2Bh1aJ4"}},{"cell_type":"markdown","source":["# USE BOOK_RECOMMEND_SYSTEM"],"metadata":{"id":"QwAZwjiy1bWS"}},{"cell_type":"code","source":["user_name = '글월마야'\n","emotion = 0.67\n","sentence = '여행가고 싶다. 훌쩍 떠나고 싶다. 해외 여행 가고 싶다.'\n","user_read = ['9772799628000', '9791198375308']  # 사용자가 읽었던 책 isbn13\n","\n","# 사용자의 선호장르\n","genres = ['시대', '전쟁', '과학']\n","mood = ['열정', '도전']\n","interest = ['영화', '생각', '성공', '심리', '동물', '시간', '사진', '여행', '인간', '시', '그림', '미술']"],"metadata":{"id":"fDaImt4I12DJ","executionInfo":{"status":"ok","timestamp":1700321490340,"user_tz":-540,"elapsed":285,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":["## 사용자 리뷰 데이터 5권 전\n","* 사용자가 적은 문장 기반 책 추천 - 10권\n","* 회원가입 시 사용자의 선호장르 기반 책 추천 - 10권"],"metadata":{"id":"SR-49RQR1hWG"}},{"cell_type":"code","source":["def recommend_books_under_five_reviews(sentence, user_read, emotion):\n","    # 문장에 대해 컨텐츠 기반 필터링\n","    isbn_list_by_sentence = recommend_books_based_on_sentence(sentence, user_read)\n","    # 선호장르 기반 책 추천\n","    isbn_list_by_feature = user_features_recommended_books(genres, mood, interest, user_read)\n","\n","    # 두 리스트를 합치고 중복 제거\n","    isbn_list = list(set(isbn_list_by_book + isbn_list_by_feature))\n","\n","    # 각 isbn에 대한 감성 점수의 차이 계산\n","    isbn_with_emotion_diff = [(isbn, abs(data.loc[data['isbn_id'] == isbn, 'emotion_score'].values[0] - emotion)) for isbn in isbn_list]\n","\n","    # 감성 점수의 차이가 최소인 순서로 정렬\n","    isbn_with_emotion_diff_sorted = sorted(isbn_with_emotion_diff, key=lambda x: x[1])\n","\n","    # 차이가 가장 적은 상위 3권의 isbn 반환\n","    return [isbn for isbn, diff in isbn_with_emotion_diff_sorted[:3]]"],"metadata":{"id":"9N8aKdo61gDV","executionInfo":{"status":"ok","timestamp":1700321942268,"user_tz":-540,"elapsed":414,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["recommend_books_under_five_reviews(sentence, user_read, emotion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_u-aQt7l5bId","executionInfo":{"status":"ok","timestamp":1700321942710,"user_tz":-540,"elapsed":1,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"43b5200c-a1a7-43d1-f2ad-491ef67174b0"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['9788934985051', '9788954685887', '9791168030046']"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["## 사용자 리뷰 데이터 5권 이상\n","* 사용자가 적은 문장 기반 책 추천 - 10권\n","\n","* 사용자 리뷰 데이터 기반 책 추천 - 10권\n","* 사용자 리뷰 데이터 기반 책 추천 10권 미만\n","    *  사용자 리뷰 데이터 기반 책 + 사용자가 읽었던 책 중 하나를 기반으로 책 추천\n","    * 하나의 책을 기반으로 유사한 책 추천\n","    * 하나의 책은 사용자가 읽었던 책 중 가장 평점이 높은 책을 이용.\n"],"metadata":{"id":"hfLY9dU_9fgw"}},{"cell_type":"code","source":["# 사용자가 읽었던 책 중 가장 평점이 높은 책\n","user_prefer_isbn = '9791198173898'\n","\n","def recommend_books_over_five_reviews(sentence, user_name, user_read, user_prefer_isbn, emotion):\n","    # 문장에 대해 컨텐츠 기반 필터링\n","    isbn_list_by_sentence = recommend_books_based_on_sentence(sentence, user_read)\n","\n","    # 사용자 리뷰 데이터 기반 책 추천\n","    isbn_list_by_review = get_user_recommendations(user_name)\n","\n","    # isbn_list_by_review이 10권 이하라면,\n","    # 사용자 선호 도서 기반 책 추천을 통해 10권이 되도록 책 리스트를 추가\n","    if len(isbn_list_by_review) < 10:\n","        more_isbn = 10 - len(isbn_list_by_review)\n","        isbn_list_by_book = recommend_books_based_on_book(user_prefer_isbn, user_read, more_isbn)\n","    else:\n","        isbn_list_by_book = []\n","\n","    # 세 리스트를 합치고 중복 제거\n","    isbn_list = list(set(isbn_list_by_sentence + isbn_list_by_review + isbn_list_by_book))\n","\n","    # 각 isbn에 대한 감성 점수의 차이 계산\n","    isbn_with_emotion_diff = [(isbn, abs(data[data['isbn_id'] == isbn]['emotion_score'].values[0] - emotion)) for isbn in isbn_list]\n","\n","    # 감성 점수의 차이가 최소인 순서로 정렬\n","    isbn_with_emotion_diff_sorted = sorted(isbn_with_emotion_diff, key=lambda x: x[1])\n","\n","    # 차이가 가장 적은 상위 3권의 isbn 반환\n","    return [isbn for isbn, diff in isbn_with_emotion_diff_sorted[:3]]\n",""],"metadata":{"id":"IicJiGX29TzA","executionInfo":{"status":"ok","timestamp":1700322885042,"user_tz":-540,"elapsed":4,"user":{"displayName":"차하린","userId":"08451484668046032097"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["recommend_books_over_five_reviews(sentence, user_name, user_read, user_prefer_isbn, emotion)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-mJtftHAMzD","executionInfo":{"status":"ok","timestamp":1700322891206,"user_tz":-540,"elapsed":315,"user":{"displayName":"차하린","userId":"08451484668046032097"}},"outputId":"34be31fc-9973-48bd-fd08-f956391a7445"},"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['9791167790996', '9788950987756', '9788950997519']"]},"metadata":{},"execution_count":106}]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"7NNdEnZZANRi"}},{"cell_type":"markdown","source":["# 추후 수정해야 할 점\n","* 사용자가 읽었던 책 중 가장 평점이 높았던 책 구하기\n","* 사용자 선호 장르 어떻게 데이터 받아올 것인지\n","* 사용자가 읽었던 책 isbn 어떻게 받아올 것인지/저장할 것인지\n","* 등..?"],"metadata":{"id":"blS3RqeqAJX1"}},{"cell_type":"code","source":[],"metadata":{"id":"Xz65vj5BJwsd"},"execution_count":null,"outputs":[]}]}